{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc41abcd-463c-4ec7-9bf3-8a1f01289f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "from Transformer import Transformer\n",
    "from TranslationDataset import TranslationDataset, create_train_val_dataloaders\n",
    "from Optimizer import CustomOptim\n",
    "from itertools import islice\n",
    "import json\n",
    "import csv\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from utils import set_seed, ensure_directory_exists, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59cba58-d514-4697-8cf0-b9fa594bcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to the experiment configuration; set the values in the config file to execute a new experiment\n",
    "CONFIG_FILE = \"ex_config-1-extension\"\n",
    "CONFIG_PATH = \"config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43410b-af9a-4d13-988a-ba60d1368755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducability\n",
    "set_seed(2630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41189072-61ff-4f37-bbfd-e9507fff8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and load the JSON file into a dictionary\n",
    "config_path = os.path.join(CONFIG_PATH,f\"{CONFIG_FILE}.json\")\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7530dc0-fa34-4d3f-9bb7-8861d4de90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES FROM CONFIG FILE THAT CONTROL EXPERIMENT RUN\n",
    "pytorch_cuda_config = config.get('pytorch_cuda','max_split_size_mb:128')\n",
    "corpus_path_config = config.get('corpus_path','/corpus/df_encoded.pkl')\n",
    "bpe_model_path_config = config.get('bpe_model_path','/bpe/bpe_model.model')\n",
    "results_path_config = config.get('results','results')\n",
    "    \n",
    "batch_size_config = config.get('batch_size',16)\n",
    "dataset_value_split_config = config.get('dataset_value_split',0.1)\n",
    "\n",
    "lr_config = config.get('lr',1e-4)\n",
    "beta1_config = config.get('beta1',0.9)\n",
    "beta2_config = config.get('beta2',0.98)\n",
    "eps_config = config.get('eps',1e-9)\n",
    "warmup_steps_config = config.get('warmup_steps',4000)\n",
    "lr_factor_config = config.get('lr_factor',1)\n",
    "\n",
    "num_epochs_config = config.get('num_epochs', 10)\n",
    "total_training_steps_config = config.get('total_training_steps', 100000)\n",
    "model_save_path_config = config.get('model_save_path','/models')\n",
    "save_interval_in_minutes_config = config.get('save_interval_in_minutes',10)\n",
    "average_model_weight_num_config = config.get('average_model_weight_num',5)\n",
    "    \n",
    "beam_size_config = config.get('beam_size',4)\n",
    "len_penalty_alpha_config = config.get('len_penalty_alpha',0.6)\n",
    "max_len_a_config = config.get('max_len_a',1)\n",
    "max_len_b_config = config.get('max_len_b',50)\n",
    "\n",
    "d_model_config = config.get('d_model_config',512)\n",
    "    \n",
    "d_dec_ff_inner_config = config.get('d_dec_ff_inner',2048)\n",
    "t_dec_heads_config = config.get('t_dec_heads',8)\n",
    "t_dec_layer_num_config = config.get('t_dec_layer_num',6)\n",
    "    \n",
    "d_enc_ff_inner_config = config.get('d_enc_ff_inner',2048)\n",
    "t_enc_heads_config = config.get('t_enc_heads',8)\n",
    "t_enc_layer_num_config = config.get('t_enc_layer_num',6)\n",
    "    \n",
    "d_query_key_head_config = config.get('d_query_key_head',64)\n",
    "d_value_head_config = config.get('d_value_head',64)\n",
    "    \n",
    "t_dropout_config = config.get('t_dropout',0.1)\n",
    "t_dot_product_config = config.get('t_dot_product',True)\n",
    "if t_dot_product_config == 1:\n",
    "    t_dot_product_config = True\n",
    "else:\n",
    "    t_dot_product_config = False\n",
    "label_smoothing_config = config.get('label_smoothing',0.1)\n",
    "\n",
    "beam_size_config = config.get('beam_size',4)\n",
    "len_penalty_alpha_config = config.get('len_penalty_alpha','max_split_size_mb:128')\n",
    "max_len_a_config = config.get('max_len_a','max_split_size_mb:128')\n",
    "max_len_b_config = config.get('max_len_b','max_split_size_mb:128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6325e6-4e1b-4908-a5c7-5dc51c072226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT EXPERIMENT RUN  \n",
    "# set general training parameters\n",
    "num_epochs = num_epochs_config\n",
    "total_training_steps = total_training_steps_config\n",
    "model_save_path = model_save_path_config\n",
    "results_save_path = results_path_config\n",
    "save_interval_in_minutes = save_interval_in_minutes_config\n",
    "average_model_weight_num = average_model_weight_num_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fecd6c-fac2-40ed-b8db-86b400b6eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda configuration for experiments\n",
    "print(f\"Cuda allocation configuration is: {pytorch_cuda_config} ...\")\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = pytorch_cuda_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cc5b7-c09a-44d0-9385-9987dd010241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus for experiment\n",
    "print(f\"Loading corpus from: {corpus_path_config} ...\")\n",
    "df_corpus = pd.read_pickle(corpus_path_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cc7e5-8c9d-43f8-b312-8d4e8b289008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bpe model for experiment\n",
    "print(f\"Loading BPE model from: {bpe_model_path_config} ...\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(bpe_model_path_config)\n",
    "\n",
    "# create variables for model from bpe model\n",
    "sb_vocab_size = sp.get_piece_size()\n",
    "sb_vocab_list = [sp.id_to_piece(i) for i in range(sb_vocab_size)]\n",
    "sb_vocab_dict = {sb_vocab_list[i]: i for i in range(sb_vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26948be-9ac7-4cd2-925d-bd1525e4d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataset\n",
    "print(\"Creating dataset ...\")\n",
    "dataset = TranslationDataset(df_corpus, sb_vocab_list)\n",
    "print(\"Creating data loaders ...\")\n",
    "train_dataloader, val_dataloader = create_train_val_dataloaders(\n",
    "    dataset,\n",
    "    batch_size=batch_size_config,\n",
    "    vocab=sb_vocab_dict,\n",
    "    val_split=dataset_value_split_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385492eb-c3e4-4a0e-acc8-84776cdf6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device for experiment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393fe62-d922-4978-9bcd-9be130b0a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "print(\"Initializing model ...\")\n",
    "model = Transformer(\n",
    "    n_vocab_len=sb_vocab_size,\n",
    "    i_vocab_padding=sb_vocab_dict['<mask>'],\n",
    "    d_model=d_model_config,\n",
    "    device=device,\n",
    "    d_dec_ff_inner=d_dec_ff_inner_config,\n",
    "    t_dec_heads=t_dec_heads_config,\n",
    "    t_dec_layer_num=t_dec_layer_num_config,\n",
    "    d_enc_ff_inner=d_enc_ff_inner_config,\n",
    "    t_enc_heads=t_enc_heads_config, \n",
    "    t_enc_layer_num=t_enc_layer_num_config,\n",
    "    d_query_key_head=d_query_key_head_config,\n",
    "    d_value_head=d_value_head_config,\n",
    "    t_dropout=t_dropout_config,\n",
    "    t_dot_product=t_dot_product_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48587939-e337-4c38-b020-c71d9d1cf9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer\n",
    "print(\"Initializing optimizer ...\")\n",
    "optimizer = CustomOptim(\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=lr_config, betas=(beta1_config, beta2_config), eps=eps_config),\n",
    "    lr=lr_config,\n",
    "    beta1=beta1_config,\n",
    "    beta2=beta2_config,\n",
    "    eps=eps_config,\n",
    "    d_model=sb_vocab_size,\n",
    "    n_warmup_steps=warmup_steps_config, \n",
    "    lr_factor=lr_factor_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2614bfd-0300-43a2-8155-b17fb01f3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=sb_vocab_dict['<mask>'],label_smoothing=label_smoothing_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5996fd-d952-4860-8b19-b66bae3596f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the directories for storing the models and results exist\n",
    "ensure_directory_exists(results_save_path)\n",
    "ensure_directory_exists(model_save_path)\n",
    "                            \n",
    "# create results file for training and validation to ease plotting\n",
    "train_results_path = os.path.join(results_save_path, f\"{CONFIG_FILE}_train_results.csv\")\n",
    "validation_results_path = os.path.join(results_save_path, f\"{CONFIG_FILE}_validation_results.csv\")\n",
    "\n",
    "# create the files with headers\n",
    "with open(train_results_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Epoch\", \"Step\", \"Loss\", \"Learning Rate\"])\n",
    "with open(validation_results_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Epoch\",\"TrainPerplexity\", \"ValidPerplexity\", \"Bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3bc06-f5ba-436e-a263-0bc7985602f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(config_file, model, dataloader, optimizer, criterion, device, clip, save_path_prefix, save_interval_in_minutes,total_training_steps,results,epoch,max_train_loop_steps):\n",
    "    global in_eval\n",
    "    if in_eval:\n",
    "        return\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm(dataloader, total=len(dataloader), position=0, leave=True)\n",
    "    output = None\n",
    "\n",
    "    global batch_start\n",
    "\n",
    "    last_save_time = time.time()\n",
    "    \n",
    "    # caculate how many batches are left in this epoch\n",
    "    step = batch_start % max_train_loop_steps\n",
    "    for batch_idx, batch in enumerate(islice(tk0, step, max_train_loop_steps)):\n",
    "\n",
    "        # in case the loop gets restarted we have to prematurely stop the training loop\n",
    "        if step >= max_train_loop_steps:\n",
    "            break\n",
    "\n",
    "        # in case we reach the end point before the entire epoch training is completed\n",
    "        if batch_start >= total_training_steps:\n",
    "            break\n",
    "        \n",
    "        source = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(source, target[:, :-1])\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(\n",
    "            output.view(-1, output.size(-1)),  # (batch_size * (target_seq_len - 1), vocab_size)\n",
    "            target[:, 1:].contiguous().view(-1)  # (batch_size * (target_seq_len - 1))\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch_start += 1\n",
    "        step += 1\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # clip gradients to avoid exploding gradients issue\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save progress for plotting\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                f'Batch: {step+1}, Loss: {loss.item():.4f}, Learning Rate: {optimizer.get_lr():.7f}')\n",
    "            # open writer to training results\n",
    "            with open(results, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([epoch, step, loss.item(), optimizer.get_lr()])\n",
    "            \n",
    "        # Save model every interval\n",
    "        if time.time() - last_save_time >= save_interval_in_minutes * 60:\n",
    "            save_checkpoint(model,optimizer,epoch,save_path_prefix,step,config_file)\n",
    "            last_save_time = time.time()\n",
    "\n",
    "        tk0.set_postfix(loss=total_loss / max_train_loop_steps)\n",
    "    tk0.close()\n",
    "    perplexity = np.exp(total_loss / step)\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e15c1-8991-433b-b366-e37a1193c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(config_file, model, dataloader, criterion, device, sp, epoch,max_train_loop_steps,\n",
    "                                              beam_size, len_penalty_alpha, max_len_a, max_len_b):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "    global in_eval\n",
    "\n",
    "    in_eval = True\n",
    "    tk0 = tqdm(dataloader, total=len(dataloader), position=0, leave=True)\n",
    "    total_steps = int(max_train_loop_steps*0.3)\n",
    "    with torch.no_grad():\n",
    "        for batch in islice(tk0, 0, total_steps):\n",
    "            source = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(source, target[:, :-1])\n",
    "            #translation = model.translate(source,beam_size, len_penalty_alpha, max_len_a, max_len_b)\n",
    "\n",
    "            # calculate the loss\n",
    "            loss = criterion(\n",
    "                output.view(-1, output.size(-1)),  # (batch_size * (target_seq_len - 1), vocab_size)\n",
    "                target[:, 1:].contiguous().view(-1)  # (batch_size * (target_seq_len - 1))\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            output = output.argmax(dim=-1)\n",
    "            target = target[:, 1:]\n",
    "\n",
    "            # converting the ids to tokens for bleu score\n",
    "            target_tokens = sp.encode_as_pieces(sp.decode(target[0].cpu().tolist()))\n",
    "            translation_tokens = sp.encode_as_pieces(sp.decode(output[0].cpu().tolist()))\n",
    "            \n",
    "            print(\"Expected Output:\", target_tokens)\n",
    "            print(\"Predicted Output:\", translation_tokens)\n",
    "            \n",
    "            hypotheses += translation_tokens\n",
    "            references += [[token] for token in target_tokens if token != '<mask>']\n",
    "            \n",
    "            tk0.set_postfix(loss=total_loss / steps)\n",
    "    tk0.close()\n",
    "    perplexity = np.exp(total_loss / total_steps)\n",
    "    references = [[[item[0] for item in references]]]\n",
    "    hypotheses = [hypotheses]\n",
    "    # Compute the BLEU score\n",
    "    bleu = bleu_score(candidate_corpus=hypotheses, references_corpus=references)\n",
    "\n",
    "    in_eval = False\n",
    "    \n",
    "    return perplexity, bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45485737-f100-4106-a5bc-81e5fe101c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(config_file, model, optimizer, criterion, train_dataloader, val_dataloader, num_epochs, total_training_steps,\n",
    "                      save_path_prefix, save_interval_in_minutes, results_save_path, average_model_weight_num, sp, device,\n",
    "                     beam_size, len_penalty_alpha, max_len_a, max_len_b,es_patience=5):\n",
    "    \n",
    "    global best_bleu\n",
    "    patience = 0\n",
    "    clip = 1.0\n",
    "    max_train_loop_steps = total_training_steps // num_epochs\n",
    "    global epoch_start\n",
    "    \n",
    "    for epoch in range(epoch_start, num_epochs+1):\n",
    "\n",
    "        # one epoch training\n",
    "        train_perplexity = train_fn(config_file, model, train_dataloader, optimizer, criterion, device, clip, save_path_prefix, save_interval_in_minutes,total_training_steps,os.path.join(results_save_path,f\"{config_file}_train_results.csv\"),epoch,max_train_loop_steps)\n",
    "        \n",
    "        # one epoch validation\n",
    "        valid_perplexity, valid_bleu = eval_fn(config_file, model, val_dataloader, criterion, device, sp, epoch,max_train_loop_steps,\n",
    "                                              beam_size, len_penalty_alpha, max_len_a, max_len_b)\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Train perplexity: {train_perplexity:.4f}, Valid perplexity: {valid_perplexity:.4f}, Valid BLEU4: {valid_bleu:.4f}')\n",
    "        with open(os.path.join(results_save_path, f\"{config_file}_validation_results.csv\"), mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, train_perplexity,valid_perplexity, valid_bleu])\n",
    "        \n",
    "        # early stopping mechanism\n",
    "        is_best = valid_bleu > best_bleu\n",
    "        if is_best:\n",
    "            print(f'BLEU score improved ({best_bleu:.4f} -> {valid_bleu:.4f}). Saving Model!')\n",
    "            best_bleu = valid_bleu\n",
    "            patience = 0\n",
    "            save_checkpoint(model, optimizer, epoch, save_path_prefix, config_file=config_file)\n",
    "        else:\n",
    "            patience += 1\n",
    "            print(f'Early stopping counter: {patience} out of {es_patience}')\n",
    "            if patience == es_patience:\n",
    "                print(f'Early stopping! Best BLEU: {best_bleu:.4f}')\n",
    "                break\n",
    "        epoch_start +=1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab08b63-5c5b-4aa1-a5c9-6f5d84cbe087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TRAINING\n",
    "# Training tracking\n",
    "batch_start = 0\n",
    "epoch_start = 0\n",
    "in_eval = False\n",
    "best_bleu = float('-inf')\n",
    "start_time = time.time()  # Total training start time\n",
    "    \n",
    "while True:\n",
    "    print(f\"Inside while with batch_start = {batch_start}\")\n",
    "    try:\n",
    "        print(\"Starting training!\")\n",
    "        train_transformer(config_file=CONFIG_FILE,\n",
    "                               model=model,\n",
    "                               optimizer=optimizer,\n",
    "                               criterion=criterion,\n",
    "                               train_dataloader=train_dataloader,\n",
    "                               val_dataloader=val_dataloader,\n",
    "                               num_epochs=num_epochs,\n",
    "                               total_training_steps=total_training_steps,\n",
    "                               save_path_prefix=model_save_path,\n",
    "                               save_interval_in_minutes=save_interval_in_minutes,\n",
    "                               results_save_path=results_save_path,\n",
    "                               average_model_weight_num=average_model_weight_num,\n",
    "                               sp=sp,\n",
    "                               es_patience=5,\n",
    "                               device=device,\n",
    "                               beam_size=beam_size,\n",
    "                               len_penalty_alpha=len_penalty_alpha,\n",
    "                               max_len_a=max_len_a,\n",
    "                               max_len_b=max_len_b\n",
    "                              )\n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        print(f\"Skipping to: {batch_start}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "\n",
    "    print(f\"The complete training took {hours:02}:{minutes:02}:{seconds:02} (HH:MM:SS).\")\n",
    "    save_checkpoint(model, optimizer, 'end', model_save_path, config_file=CONFIG_FILE)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
