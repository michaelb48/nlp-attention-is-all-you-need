{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0c82f95a-42ee-4e1a-bec5-5a1eff24dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "from Transformer import Transformer\n",
    "from TranslationDataset import TranslationDataset, create_train_val_dataloaders\n",
    "from Optimizer import CustomOptim\n",
    "from itertools import islice\n",
    "import json\n",
    "import csv\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from utils import set_seed, ensure_directory_exists, save_checkpoint, load_state_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5c7e44d9-1ab7-4a5b-aea4-57899b3696ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2630)\n",
    "\n",
    "CONFIG_FILE = \"ex_config-4\"\n",
    "CONFIG_PATH = \"config\"\n",
    "\n",
    "# Open and load the JSON file into a dictionary\n",
    "config_path = os.path.join(CONFIG_PATH,f\"{CONFIG_FILE}.json\")\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# VARIABLES FROM CONFIG FILE THAT CONTROL EXPERIMENT RUN\n",
    "pytorch_cuda_config = config.get('pytorch_cuda','max_split_size_mb:128')\n",
    "\n",
    "corpus_path_config = config.get('corpus_path','/corpus/df_encoded.pkl')\n",
    "bpe_model_path_config = config.get('bpe_model_path','/bpe/bpe_model.model')\n",
    "results_path_config = config.get('results','results')\n",
    "\n",
    "batch_size_config = config.get('batch_size',16)\n",
    "dataset_value_split_config = config.get('dataset_value_split',0.1)\n",
    "\n",
    "lr_config = config.get('lr',1e-4)\n",
    "beta1_config = config.get('beta1',0.9)\n",
    "beta2_config = config.get('beta2',0.98)\n",
    "eps_config = config.get('eps',1e-9)\n",
    "warmup_steps_config = config.get('warmup_steps',4000)\n",
    "lr_factor_config = config.get('lr_factor',1)\n",
    "\n",
    "num_epochs_config = config.get('num_epochs', 10)\n",
    "total_training_steps_config = config.get('total_training_steps', 100000)\n",
    "model_save_path_config = config.get('model_save_path','/models')\n",
    "save_interval_in_minutes_config = config.get('save_interval_in_minutes',10)\n",
    "average_model_weight_num_config = config.get('average_model_weight_num',5)\n",
    "\n",
    "beam_size_config = config.get('beam_size',4)\n",
    "len_penalty_alpha_config = config.get('len_penalty_alpha',0.6)\n",
    "max_len_a_config = config.get('max_len_a',1)\n",
    "max_len_b_config = config.get('max_len_b',50)\n",
    "\n",
    "d_model_config = config.get('d_model_config',512)\n",
    "\n",
    "d_dec_ff_inner_config = config.get('d_dec_ff_inner',2048)\n",
    "t_dec_heads_config = config.get('t_dec_heads',8)\n",
    "t_dec_layer_num_config = config.get('t_dec_layer_num',6)\n",
    "\n",
    "d_enc_ff_inner_config = config.get('d_enc_ff_inner',2048)\n",
    "t_enc_heads_config = config.get('t_enc_heads',8)\n",
    "t_enc_layer_num_config = config.get('t_enc_layer_num',6)\n",
    "\n",
    "d_query_key_head_config = config.get('d_query_key_head',64)\n",
    "d_value_head_config = config.get('d_value_head',64)\n",
    "\n",
    "t_dropout_config = config.get('t_dropout',0.1)\n",
    "t_dot_product_config = config.get('t_dot_product',True)\n",
    "if t_dot_product_config == 1:\n",
    "    t_dot_product_config = True\n",
    "else:\n",
    "    t_dot_product_config = False\n",
    "label_smoothing_config = config.get('label_smoothing',0.1)\n",
    "\n",
    "beam_size_config = config.get('beam_size',4)\n",
    "len_penalty_alpha_config = config.get('len_penalty_alpha','max_split_size_mb:128')\n",
    "max_len_a_config = config.get('max_len_a','max_split_size_mb:128')\n",
    "max_len_b_config = config.get('max_len_b','max_split_size_mb:128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38312061-8a8c-4405-86fb-74a1f14477bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BPE model from: ../bpe/bpe_model.model ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading BPE model from: {bpe_model_path_config} ...\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(bpe_model_path_config)\n",
    "\n",
    "# create variables for model from bpe model\n",
    "sb_vocab_size = sp.get_piece_size()\n",
    "sb_vocab_list = [sp.id_to_piece(i) for i in range(sb_vocab_size)]\n",
    "sb_vocab_dict = {sb_vocab_list[i]: i for i in range(sb_vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aa947636-c014-422b-934c-d8d2b96f65f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing model ...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# initialize the model\n",
    "print(\"Initializing model ...\")\n",
    "model = Transformer(\n",
    "    n_vocab_len=sb_vocab_size,\n",
    "    i_vocab_padding=sb_vocab_dict['<mask>'],\n",
    "    d_model=d_model_config,\n",
    "    device=device,\n",
    "    d_dec_ff_inner=d_dec_ff_inner_config,\n",
    "    t_dec_heads=t_dec_heads_config,\n",
    "    t_dec_layer_num=t_dec_layer_num_config,\n",
    "    d_enc_ff_inner=d_enc_ff_inner_config,\n",
    "    t_enc_heads=t_enc_heads_config, \n",
    "    t_enc_layer_num=t_enc_layer_num_config,\n",
    "    d_query_key_head=d_query_key_head_config,\n",
    "    d_value_head=d_value_head_config,\n",
    "    t_dropout=t_dropout_config,\n",
    "    t_dot_product=t_dot_product_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6306627-e93f-4288-a77e-e36827316d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load('models/' + 'ex_config-4_model_epoch_end.pth', map_location=torch.device(device))  # Use \"cuda\" if on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "40bf5401-eaee-4673-bed5-511c08c1ab3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5861b415-fcbf-4ebc-baed-140cbc8c31bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (vocab_embedding): Embedding(37000, 512, padding_idx=5)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layer_stack): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention_sublayer): MHAttentionSublayer(\n",
       "          (multi_headed_attention): MHAttention(\n",
       "            (key_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (query_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (value_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (scaled_dot_product_attention): ScaledDotProductAttention()\n",
       "            (concat_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (feed_forward_sublayer): FeedForwardSublayer(\n",
       "          (linear_proj): FeedForwardUnit(\n",
       "            (d_model_to_d_inner): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (relu): ReLU()\n",
       "            (d_inner_to_d_model): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (feed_forward_stack): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_layer_stack): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (masked_attention_sublayer): MHAttentionSublayer(\n",
       "          (multi_headed_attention): MHAttention(\n",
       "            (key_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (query_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (value_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (scaled_dot_product_attention): ScaledDotProductAttention()\n",
       "            (concat_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (attention_sublayer): MHAttentionSublayer(\n",
       "          (multi_headed_attention): MHAttention(\n",
       "            (key_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (query_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (value_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (scaled_dot_product_attention): ScaledDotProductAttention()\n",
       "            (concat_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (feed_forward_sublayer): FeedForwardSublayer(\n",
       "          (linear_proj): FeedForwardUnit(\n",
       "            (d_model_to_d_inner): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (relu): ReLU()\n",
       "            (d_inner_to_d_model): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (feed_forward_stack): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (normalization): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (linear_to_vocab): Linear(in_features=512, out_features=37000, bias=False)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44ad078d-b3e4-400c-addc-7fe43c6f30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def beam_search(model, sp, input_sentence, beam_width=4, max_length=50):\n",
    "    \"\"\"\n",
    "    Beam search for inference using a Transformer model with SentencePiece tokenizer.\n",
    "    Args:\n",
    "        model: Transformer model (expects input + decoder input).\n",
    "        sp: SentencePiece tokenizer.\n",
    "        input_sentence: Sentence to translate/generate.\n",
    "        beam_width: Number of beams to keep.\n",
    "        max_length: Max output length.\n",
    "    Returns:\n",
    "        Best decoded sentence.\n",
    "    \"\"\"\n",
    "    #print(model.parameters)\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    input_ids = sp.encode(input_sentence)\n",
    "\n",
    "    start_token = sp.piece_to_id(\"<s>\")\n",
    "    end_token = sp.piece_to_id(\"</s>\")\n",
    "\n",
    "    # Adding sos and end tokens to our encoder sequence\n",
    "    input_ids.insert(0, start_token)\n",
    "    input_ids.append(end_token)\n",
    "    input_ids = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # Initializing beams to the start token\n",
    "    beams = [(torch.tensor([start_token]).to(device), 0.0)]\n",
    "\n",
    "    # Going through all possible beams until the eos tokens are produced in all beams or until max length is reached\n",
    "    for _ in range(max_length):\n",
    "        new_beams = []\n",
    "        \n",
    "        for seq, score in beams:\n",
    "            if seq[-1].item() == end_token:\n",
    "                new_beams.append((seq, score))\n",
    "                continue\n",
    "                \n",
    "            decoder_input = seq.unsqueeze(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(input_ids, decoder_input)  # (batch_size, seq_len, vocab_size)\n",
    "                logits = output[:, -1, :]  # (batch_size, vocab_size)\n",
    "            \n",
    "            # Converting logits to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Selecting top-k tokens\n",
    "            topk_probs, topk_indices = torch.topk(probs[0], beam_width)  # Remove batch dimension\n",
    "            \n",
    "            # Adding k tokens to their corresponding beams\n",
    "            for i in range(beam_width):\n",
    "                new_token = topk_indices[i].unsqueeze(0) \n",
    "                new_seq = torch.cat([seq, new_token], dim=0)\n",
    "                new_score = score + torch.log(topk_probs[i]).item() # Adding the logits of the added token as the score\n",
    "                new_beams.append((new_seq, new_score))\n",
    "        \n",
    "        # Keeping top-k beams\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        \n",
    "        # Stoping if all beams end with eos\n",
    "        if all(seq[-1].item() == end_token for seq, _ in beams):\n",
    "            break\n",
    "    \n",
    "    # Return best sequence\n",
    "    best_seq = beams[0][0].cpu().tolist()\n",
    "    return sp.decode(best_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9bf32e9a-79b2-43ce-900e-ccae1bbb0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Today is a beautiful day to train a Transformer\n",
      "Generated Output: Heute ist ein sch√∂nen Tag, um einen Transform zu machen.\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Today is a beautiful day to train a Transformer\"\n",
    "print(\"Input: \", input_sentence)\n",
    "output_sentence = beam_search(model, sp, input_sentence)\n",
    "print(\"Generated Output:\", output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09072d-8d9b-4e1f-a31e-59dcfe73a8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
