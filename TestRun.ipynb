{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd443515-c775-402d-a34b-71851b52a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "from Transformer import Transformer\n",
    "from TranslationDataset import TranslationDataset, create_train_val_dataloaders\n",
    "from itertools import islice\n",
    "import json\n",
    "import csv\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from utils import set_seed, ensure_directory_exists,load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0af80a4-f099-4cc3-9350-1cbda8428bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to the test configuration; set the values in the config file to execute a new test\n",
    "CONFIG_FILE = \"ex_config-1\"\n",
    "CONFIG_PATH = \"config\"\n",
    "TEST_MODEL_PATH = \"../groups/192.039-2024W/attentiondeficit/training-results/models/ex_config-2_model_epoch_end.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d74f5f-67e5-44d0-86f7-10599ea0b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducability\n",
    "set_seed(2630)\n",
    "    \n",
    "# Open and load the JSON file into a dictionary\n",
    "config_path = os.path.join(CONFIG_PATH,f\"{CONFIG_FILE}.json\")\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d671106-c8a3-4c30-b21a-e9fb0e2aa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES FROM CONFIG FILE THAT CONTROL EXPERIMENT RUN\n",
    "pytorch_cuda_config = config.get('pytorch_cuda','max_split_size_mb:128')\n",
    "\n",
    "corpus_path_config = config.get('testcorpus_path','/test_corpus/df_encoded.pkl')\n",
    "bpe_model_path_config = config.get('bpe_model_path','/bpe/bpe_model.model')\n",
    "results_path_config = config.get('results_path','results')\n",
    "    \n",
    "batch_size_config = config.get('batch_size',16)\n",
    "dataset_value_split_config = config.get('dataset_value_split',0.3)\n",
    "\n",
    "label_smoothing_config = config.get('label_smoothing',0.1)\n",
    "    \n",
    "total_test_steps_config = config.get('total_test_steps', 30000)\n",
    "\n",
    "d_model_config = config.get('d_model_config',512)\n",
    "    \n",
    "d_dec_ff_inner_config = config.get('d_dec_ff_inner',2048)\n",
    "t_dec_heads_config = config.get('t_dec_heads',8)\n",
    "t_dec_layer_num_config = config.get('t_dec_layer_num',6)\n",
    "    \n",
    "d_enc_ff_inner_config = config.get('d_enc_ff_inner',2048)\n",
    "t_enc_heads_config = config.get('t_enc_heads',8)\n",
    "t_enc_layer_num_config = config.get('t_enc_layer_num',6)\n",
    "    \n",
    "d_query_key_head_config = config.get('d_query_key_head',64)\n",
    "d_value_head_config = config.get('d_value_head',64)\n",
    "    \n",
    "t_dropout_config = config.get('t_dropout',0.1)\n",
    "t_dot_product_config = config.get('t_dot_product',True)\n",
    "if t_dot_product_config == 1:\n",
    "    t_dot_product_config = True\n",
    "else:\n",
    "    t_dot_product_config = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c0f804-6d32-424c-b6bc-1729163ee9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda allocation configuration is: max_split_size_mb:128 ...\n"
     ]
    }
   ],
   "source": [
    "# set general training parameters\n",
    "total_test_steps = total_test_steps_config\n",
    "results_save_path = results_path_config\n",
    "    \n",
    "# set cuda configuration for experiments\n",
    "print(f\"Cuda allocation configuration is: {pytorch_cuda_config} ...\")\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = pytorch_cuda_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386281f7-8ac3-448c-96e3-43c14c84629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus from: ../test_corpus/df_encoded.pkl ...\n"
     ]
    }
   ],
   "source": [
    "# load corpus for experiment\n",
    "print(f\"Loading corpus from: {corpus_path_config} ...\")\n",
    "df_corpus = pd.read_pickle(corpus_path_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0957e033-0a74-404f-bf82-25626900d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BPE model from: ../bpe/bpe_model.model ...\n"
     ]
    }
   ],
   "source": [
    "# load bpe model for experiment\n",
    "print(f\"Loading BPE model from: {bpe_model_path_config} ...\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(bpe_model_path_config)\n",
    "\n",
    "# create variables for model from bpe model\n",
    "sb_vocab_size = sp.get_piece_size()\n",
    "sb_vocab_list = [sp.id_to_piece(i) for i in range(sb_vocab_size)]\n",
    "sb_vocab_dict = {sb_vocab_list[i]: i for i in range(sb_vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec43bd75-ba9e-4e60-8048-409b32516fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset ...\n",
      "Creating data loaders ...\n"
     ]
    }
   ],
   "source": [
    "# initialize dataset\n",
    "print(\"Creating dataset ...\")\n",
    "dataset = TranslationDataset(df_corpus, sb_vocab_list)\n",
    "print(\"Creating data loaders ...\")\n",
    "test_dataloader, _ = create_train_val_dataloaders(\n",
    "    dataset,\n",
    "    batch_size=batch_size_config,\n",
    "    vocab=sb_vocab_dict,\n",
    "    val_split=dataset_value_split_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d40e7ea-41a3-45bf-b0ae-7b77900a5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set the device for experiment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a665d7-d299-4459-be0d-26466f06de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Loaded checkpoint from '../groups/192.039-2024W/attentiondeficit/training-results/models/ex_config-2_model_epoch_end.pth'\n",
      "Model correctly loaded.\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "print(\"Loading model ...\")\n",
    "model = Transformer(\n",
    "    n_vocab_len=sb_vocab_size,\n",
    "    i_vocab_padding=sb_vocab_dict['<mask>'],\n",
    "    d_model=d_model_config,\n",
    "    device=device,\n",
    "    d_dec_ff_inner=d_dec_ff_inner_config,\n",
    "    t_dec_heads=t_dec_heads_config,\n",
    "    t_dec_layer_num=t_dec_layer_num_config,\n",
    "    d_enc_ff_inner=d_enc_ff_inner_config,\n",
    "    t_enc_heads=t_enc_heads_config, \n",
    "    t_enc_layer_num=t_enc_layer_num_config,\n",
    "    d_query_key_head=d_query_key_head_config,\n",
    "    d_value_head=d_value_head_config,\n",
    "    t_dropout=t_dropout_config,\n",
    "    t_dot_product=t_dot_product_config\n",
    ").to(device)\n",
    "\n",
    "model = load_checkpoint(TEST_MODEL_PATH, model, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324931c4-da7c-4d93-a8f0-3f0660f04f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=sb_vocab_dict['<mask>'],label_smoothing=label_smoothing_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5beaa19-78ef-42bf-86ca-b7dc164c24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the directories for storing the results exist\n",
    "ensure_directory_exists(results_save_path)\n",
    "                            \n",
    "# create results file for testing to ease plotting\n",
    "test_results_path = os.path.join(results_save_path, f\"{CONFIG_FILE}_test_results.csv\")\n",
    "\n",
    "# create the files with headers\n",
    "with open(test_results_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"time\",\"perplexity\", \"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e1ab49-2522-4c19-92e5-e27c45c6c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(model,device,dataloader,criterion,sp,total_test_steps):\n",
    "                                   \n",
    "    model.eval()\n",
    "    global total_loss\n",
    "    global steps\n",
    "    global hypotheses\n",
    "    global references\n",
    "    \n",
    "    tk0 = tqdm(dataloader, total=len(dataloader), position=0, leave=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in islice(tk0, steps, total_test_steps):\n",
    "\n",
    "            # move sequences to device\n",
    "            source = batch[0].to(device)\n",
    "            target = batch[1].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            output = model(source, target[:, :-1])\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(\n",
    "                output.view(-1, output.size(-1)),  # (batch_size * (target_seq_len - 1), vocab_size)\n",
    "                target[:, 1:].contiguous().view(-1)  # (batch_size * (target_seq_len - 1))\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            output = output.argmax(dim=-1)\n",
    "            target = target[:, 1:]\n",
    "\n",
    "            # converting the ids to tokens for bleu score\n",
    "            target_tokens = sp.encode_as_pieces(sp.decode(target[0].cpu().tolist()))\n",
    "            pred_tokens = sp.encode_as_pieces(sp.decode(output[0].cpu().tolist()))\n",
    "            \n",
    "            hypotheses += pred_tokens\n",
    "            references += [[token] for token in target_tokens if token != '<mask>']\n",
    "            \n",
    "            tk0.set_postfix(loss=total_loss / steps)\n",
    "    tk0.close()\n",
    "    perplexity = np.exp(total_loss / total_test_steps)\n",
    "    references = [[[item[0] for item in references]]]\n",
    "    hypotheses = [hypotheses]\n",
    "    # Compute the BLEU score\n",
    "    bleu = bleu_score(candidate_corpus=hypotheses, references_corpus=references)\n",
    "    \n",
    "    return perplexity, bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83441dc-1951-43b3-9ec6-4c13a2e5489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transformer(model, device, criterion, test_dataloader, sp, total_test_steps, test_results_path):\n",
    "\n",
    "    testing_start_time = time.time()  # Total training start time\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            print(\"Starting testing!\")\n",
    "            attempt_start_time = time.time()\n",
    "            perplexity, bleu = test_fn(model=model,\n",
    "                                        device=device,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        criterion=criterion,\n",
    "                                        sp=sp,\n",
    "                                        total_test_steps = total_test_steps)\n",
    "\n",
    "            elapsed_time = time.time() - attempt_start_time\n",
    "            \n",
    "            print(f'Time in sec: {elapsed_time}, Test perplexity: {perplexity:.4f}, Test BLEU: {bleu:.4f}')\n",
    "            with open(test_results_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([elapsed_time, perplexity, bleu])\n",
    "            return elapsed_time, perplexity, bleu\n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            if attempt == 5:\n",
    "                print(f\"All test attempts failed due to memory issues. No results available.\")\n",
    "                return time.time() - testing_start_time, perplexity, bleu\n",
    "            print(f\"Test attempt {attempt} failed due to memory issues.\")\n",
    "            print(f\"Continuing test from step {steps}.\")\n",
    "            torch.cuda.empty_cache()\n",
    "            attempt += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c28ffa31-a485-450e-8156-41be2af9cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 485/191759 [00:10<1:11:46, 44.42it/s, loss=5.76]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m hypotheses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m references \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m elapsed_time, perp, bleu \u001b[38;5;241m=\u001b[39m \u001b[43mtest_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtotal_test_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_test_steps_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtest_results_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_results_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate elapsed time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m hours \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(elapsed_time \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3600\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mtest_transformer\u001b[0;34m(model, device, criterion, test_dataloader, sp, total_test_steps, test_results_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting testing!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m attempt_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m perplexity, bleu \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtotal_test_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_test_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m attempt_start_time\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime in sec: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperplexity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test BLEU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 27\u001b[0m, in \u001b[0;36mtest_fn\u001b[0;34m(model, device, dataloader, criterion, sp, total_test_steps)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# calculate the loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[1;32m     23\u001b[0m     output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),  \u001b[38;5;66;03m# (batch_size * (target_seq_len - 1), vocab_size)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     target[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size * (target_seq_len - 1))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# START TESTING\n",
    "# Testing tracking\n",
    "attempt = 1\n",
    "bleu = float('-inf')\n",
    "perplexity = float('-inf')\n",
    "total_loss = 0.0\n",
    "steps = 0\n",
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "elapsed_time, perp, bleu = test_transformer(model=model,\n",
    "                                            device=device,\n",
    "                                            test_dataloader=test_dataloader,\n",
    "                                            criterion=criterion,\n",
    "                                            sp=sp,\n",
    "                                            total_test_steps = total_test_steps_config,\n",
    "                                            test_results_path = test_results_path)\n",
    "    \n",
    "# Calculate elapsed time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(f\"The complete test took {hours:02}:{minutes:02}:{seconds:02} (HH:MM:SS).\")\n",
    "print(f'The model achieved testing perplexity: {perp:.4f} and testing BLEU: {bleu:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741118ff-70d8-48c4-95de-baa6ca1c8663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
